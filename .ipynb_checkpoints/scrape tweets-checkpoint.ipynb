{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d43b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bc12a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 1: Initialize Reddit client (using your credentials)\n",
    "def redditClient():\n",
    "    \"\"\"\n",
    "    Read-only Reddit API access (no login needed).\n",
    "    \"\"\"\n",
    "    redditClient = praw.Reddit(\n",
    "        client_id=\"EzHVeRw_MAcYTVklYzLs0g\",\n",
    "        client_secret=\"ZZG-6PzEwN-cozi4jrV9ArzjOL_KJg\",\n",
    "        password=\"Chanandler1969\",\n",
    "        user_agent=\"script:tennis.goat.analysis:v1.0 (by u/sanchanhart)\",\n",
    "        username=\"sanchanhart\"\n",
    "    )\n",
    "    return redditClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a442720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Reddit client\n",
    "def redditClient():\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=\"EzHVeRw_MAcYTVklYzLs0g\",\n",
    "        client_secret=\"ZZG-6PzEwN-cozi4jrV9ArzjOL_KJg\",\n",
    "        password=\"Chanandler1969\",\n",
    "        user_agent=\"script:tennis.goat.analysis:v1.0 (by u/sanchanhart)\",\n",
    "        username=\"sanchanhart\"\n",
    "    )\n",
    "    return reddit\n",
    "\n",
    "reddit = redditClient()\n",
    "\n",
    "# Artist-song pairs\n",
    "song_artist_pairs = [\n",
    "    (\"Apple\", \"Charli XCX\"),\n",
    "    (\"BIRDS OF A FEATHER\", \"Billie Eilish\"),\n",
    "    (\"Espresso\", \"Sabrina Carpenter\"),\n",
    "    (\"Not Like Us\", \"Kendrick Lamar\"),\n",
    "    (\"Obsessed\", \"Olivia Rodrigo\"),\n",
    "    (\"Too Sweet\", \"Hozier\"),\n",
    "    (\"APT\", \"Rose\"),\n",
    "    (\"FEIN\", \"Travis Scott\"),\n",
    "    (\"Big Dawgs\", \"Hanumankind\"),\n",
    "    (\"Mamushi\", \"Meghan Thee Stallion\")\n",
    "]\n",
    "\n",
    "# Searching across general Reddit\n",
    "subreddits = [\"all\"]\n",
    "\n",
    "# Data collection function\n",
    "def collect_posts_precise(reddit, song, artist, subreddits, limit=200):\n",
    "    collected = []\n",
    "    query = f'\"{song}\" \"{artist}\"'  # Combined query\n",
    "    for sub in subreddits:\n",
    "        try:\n",
    "            print(f\"üîç Searching Reddit for '{query}' in r/{sub}...\")\n",
    "            for post in reddit.subreddit(sub).search(query, sort='new', limit=limit):\n",
    "                collected.append({\n",
    "                    \"query\": query,\n",
    "                    \"subreddit\": sub,\n",
    "                    \"title\": post.title,\n",
    "                    \"selftext\": post.selftext,\n",
    "                    \"score\": post.score,\n",
    "                    \"num_comments\": post.num_comments,\n",
    "                    \"created_utc\": datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    \"url\": post.url\n",
    "                })\n",
    "                time.sleep(0.2)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error searching '{query}' in subreddit {sub}: {e}\")\n",
    "    return collected\n",
    "\n",
    "# Main scraping loop\n",
    "all_precise_posts = []\n",
    "for song, artist in song_artist_pairs:\n",
    "    print(f\"\\nüé∂ Collecting posts for: {song} by {artist}\")\n",
    "    posts = collect_posts_precise(reddit, song, artist, subreddits)\n",
    "    all_precise_posts.extend(posts)\n",
    "\n",
    "# Save to CSV\n",
    "df_precise = pd.DataFrame(all_precise_posts)\n",
    "df_precise.to_csv(\"reddit_precise_posts.csv\", index=False)\n",
    "print(\"\\n‚úÖ Data collection complete. Saved as reddit_precise_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5822034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Reddit client\n",
    "def redditClient():\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=\"EzHVeRw_MAcYTVklYzLs0g\",\n",
    "        client_secret=\"ZZG-6PzEwN-cozi4jrV9ArzjOL_KJg\",\n",
    "        password=\"Chanandler1969\",\n",
    "        user_agent=\"script:tennis.goat.analysis:v1.0 (by u/sanchanhart)\",\n",
    "        username=\"sanchanhart\"\n",
    "    )\n",
    "    return reddit\n",
    "\n",
    "reddit = redditClient()\n",
    "\n",
    "# Artist-song pairs\n",
    "song_artist_pairs = [\n",
    "    (\"Apple\", \"Charli XCX\"),\n",
    "    (\"BIRDS OF A FEATHER\", \"Billie Eilish\"),\n",
    "    (\"Espresso\", \"Sabrina Carpenter\"),\n",
    "    (\"Not Like Us\", \"Kendrick Lamar\"),\n",
    "    (\"Obsessed\", \"Olivia Rodrigo\"),\n",
    "    (\"Too Sweet\", \"Hozier\"),\n",
    "    (\"APT\", \"Rose\"),\n",
    "    (\"FEIN\", \"Travis Scott\"),\n",
    "    (\"Big Dawgs\", \"Hanumankind\"),\n",
    "    (\"Mamushi\", \"Meghan Thee Stallion\")\n",
    "]\n",
    "\n",
    "# Subreddits to search\n",
    "subreddits = [\"all\"]\n",
    "\n",
    "# Data collection function\n",
    "def collect_posts_precise(reddit, song, artist, subreddits, limit=200):\n",
    "    collected = []\n",
    "    query = f'\"{song}\" \"{artist}\"'  # Combined query\n",
    "    for sub in subreddits:\n",
    "        try:\n",
    "            print(f\"üîç Searching Reddit for '{query}' in r/{sub}...\")\n",
    "            for post in reddit.subreddit(sub).search(query, sort='new', limit=limit):\n",
    "                collected.append({\n",
    "                    \"query\": query,\n",
    "                    \"subreddit\": sub,\n",
    "                    \"title\": post.title,\n",
    "                    \"selftext\": post.selftext,\n",
    "                    \"author\": str(post.author),\n",
    "                    \"id\": post.id,\n",
    "                    \"score\": post.score,\n",
    "                    \"num_comments\": post.num_comments,\n",
    "                    \"created_utc\": datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    \"url\": post.url\n",
    "                })\n",
    "                time.sleep(0.2)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error searching '{query}' in r/{sub}: {e}\")\n",
    "    return collected\n",
    "\n",
    "# Main loop for all artist-song pairs\n",
    "all_precise_posts = []\n",
    "\n",
    "for song, artist in song_artist_pairs:\n",
    "    print(f\"\\nüé∂ Collecting posts for: {song} by {artist}\")\n",
    "    posts = collect_posts_precise(reddit, song, artist, subreddits)\n",
    "    all_precise_posts.extend(posts)\n",
    "\n",
    "# Convert and save\n",
    "df = pd.DataFrame(all_precise_posts)\n",
    "df = df[[\"query\", \"title\", \"selftext\", \"subreddit\", \"author\", \"score\", \"num_comments\", \"created_utc\", \"url\", \"id\"]]\n",
    "df.to_csv(\"reddit_precise_posts.csv\", index=False)\n",
    "print(\"\\n‚úÖ Data collection complete. Saved as reddit_precise_posts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a9604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Reddit client\n",
    "def redditClient():\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=\"EzHVeRw_MAcYTVklYzLs0g\",\n",
    "        client_secret=\"ZZG-6PzEwN-cozi4jrV9ArzjOL_KJg\",\n",
    "        password=\"Chanandler1969\",\n",
    "        user_agent=\"script:tennis.goat.analysis:v1.0 (by u/sanchanhart)\",\n",
    "        username=\"sanchanhart\"\n",
    "    )\n",
    "    return reddit\n",
    "\n",
    "reddit = redditClient()\n",
    "\n",
    "# Artist-song pairs\n",
    "song_artist_pairs = [\n",
    "    (\"Apple\", \"Charli XCX\"),\n",
    "    (\"BIRDS OF A FEATHER\", \"Billie Eilish\"),\n",
    "    (\"Espresso\", \"Sabrina Carpenter\"),\n",
    "    (\"Not Like Us\", \"Kendrick Lamar\"),\n",
    "    (\"Obsessed\", \"Olivia Rodrigo\"),\n",
    "    (\"Too Sweet\", \"Hozier\"),\n",
    "    (\"APT\", \"Rose\"),\n",
    "    (\"FEIN\", \"Travis Scott\"),\n",
    "    (\"Big Dawgs\", \"Hanumankind\"),\n",
    "    (\"Mamushi\", \"Meghan Thee Stallion\")\n",
    "]\n",
    "\n",
    "# Subreddits to search\n",
    "subreddits = [\"all\"]\n",
    "\n",
    "# Data collection function\n",
    "def collect_posts_precise(reddit, song, artist, subreddits, limit=200):\n",
    "    collected = []\n",
    "    query = f'\"{song}\" \"{artist}\"'\n",
    "    \n",
    "    for sub in subreddits:\n",
    "        try:\n",
    "            print(f\"üîç Searching Reddit for '{query}' in r/{sub}...\")\n",
    "            for post in reddit.subreddit(sub).search(query, sort='new', limit=limit):\n",
    "\n",
    "                # ‚úÖ Filter: Only save posts that are actual submissions with meaningful content\n",
    "                if not post.title or len(post.title.strip()) < 5:\n",
    "                    continue  # skip blank titles or short junk\n",
    "                if post.selftext and \"http\" in post.selftext.lower() and len(post.selftext.strip()) < 50:\n",
    "                    continue  # skip spam links\n",
    "                if post.author is None or str(post.author).lower() == \"automoderator\":\n",
    "                    continue  # skip bot/mod posts\n",
    "\n",
    "                try:\n",
    "                    collected.append({\n",
    "                        \"query\": query,\n",
    "                        \"subreddit\": sub,\n",
    "                        \"title\": post.title.strip(),\n",
    "                        \"selftext\": post.selftext.strip() if post.selftext else \"\",\n",
    "                        \"author\": str(post.author),\n",
    "                        \"id\": post.id,\n",
    "                        \"score\": post.score,\n",
    "                        \"num_comments\": post.num_comments,\n",
    "                        \"created_utc\": datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                        \"url\": post.url\n",
    "                    })\n",
    "                except Exception as inner_error:\n",
    "                    print(f\"‚ö†Ô∏è Skipped malformed post: {inner_error}\")\n",
    "\n",
    "                time.sleep(0.2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error searching '{query}' in subreddit {sub}: {e}\")\n",
    "\n",
    "    return collected\n",
    "\n",
    "\n",
    "# Main loop for all artist-song pairs\n",
    "all_precise_posts = []\n",
    "\n",
    "for song, artist in song_artist_pairs:\n",
    "    print(f\"\\nüé∂ Collecting posts for: {song} by {artist}\")\n",
    "    posts = collect_posts_precise(reddit, song, artist, subreddits)\n",
    "    all_precise_posts.extend(posts)\n",
    "\n",
    "# Convert and save\n",
    "df = pd.DataFrame(all_precise_posts)\n",
    "df = df[[\"query\", \"title\", \"selftext\", \"subreddit\", \"author\", \"score\", \"num_comments\", \"created_utc\", \"url\", \"id\"]]\n",
    "df.to_csv(\"reddit_precise_posts_2.csv\", index=False)\n",
    "print(\"\\n‚úÖ Data collection complete. Saved as reddit_precise_posts_2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 1: Setup Reddit client\n",
    "def redditClient():\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=\"EzHVeRw_MAcYTVklYzLs0g\",\n",
    "        client_secret=\"ZZG-6PzEwN-cozi4jrV9ArzjOL_KJg\",\n",
    "        password=\"Chanandler1969\",\n",
    "        user_agent=\"script:tennis.goat.analysis:v1.0 (by u/sanchanhart)\",\n",
    "        username=\"sanchanhart\"\n",
    "    )\n",
    "    return reddit\n",
    "\n",
    "reddit = redditClient()\n",
    "\n",
    "# Step 2: Define artists and songs\n",
    "song_artist_pairs = [\n",
    "    (\"Apple\", \"Charli XCX\"),\n",
    "    (\"BIRDS OF A FEATHER\", \"Billie Eilish\"),\n",
    "    (\"Espresso\", \"Sabrina Carpenter\"),\n",
    "    (\"Not Like Us\", \"Kendrick Lamar\"),\n",
    "    (\"Obsessed\", \"Olivia Rodrigo\"),\n",
    "    (\"Too Sweet\", \"Hozier\"),\n",
    "    (\"APT\", \"Rose\"),\n",
    "    (\"FEIN\", \"Travis Scott\"),\n",
    "    (\"Big Dawgs\", \"Hanumankind\"),\n",
    "    (\"Mamushi\", \"Meghan Thee Stallion\")\n",
    "]\n",
    "\n",
    "subreddits = [\"all\"]\n",
    "\n",
    "# Step 3: Collect comments from posts that match song + artist\n",
    "def scrape_comments_from_matching_posts(reddit, song, artist, subreddits, limit=50, max_comments=100):\n",
    "    all_comments = []\n",
    "    query = f'\"{song}\" \"{artist}\"'\n",
    "\n",
    "    for sub in subreddits:\n",
    "        print(f\"\\nüîç Searching for posts: {query} in r/{sub}\")\n",
    "        try:\n",
    "            for post in reddit.subreddit(sub).search(query, sort='new', limit=limit):\n",
    "                try:\n",
    "                    print(f\"üßµ Scraping comments from post: {post.title[:60]}\")\n",
    "\n",
    "                    post.comments.replace_more(limit=0)\n",
    "                    count = 0\n",
    "                    for comment in post.comments.list():\n",
    "                        if comment.body and comment.author:\n",
    "                            all_comments.append({\n",
    "                                \"song\": song,\n",
    "                                \"artist\": artist,\n",
    "                                \"subreddit\": sub,\n",
    "                                \"post_id\": post.id,\n",
    "                                \"post_title\": post.title,\n",
    "                                \"comment_id\": comment.id,\n",
    "                                \"author\": str(comment.author),\n",
    "                                \"body\": comment.body.strip(),\n",
    "                                \"score\": comment.score,\n",
    "                                \"created_utc\": datetime.utcfromtimestamp(comment.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                            })\n",
    "                            count += 1\n",
    "                        if count >= max_comments:\n",
    "                            break\n",
    "                    time.sleep(0.5)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Comment scraping error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Post search error in r/{sub}: {e}\")\n",
    "\n",
    "    return all_comments\n",
    "\n",
    "# Step 4: Scrape all comments\n",
    "final_comments = []\n",
    "\n",
    "for song, artist in song_artist_pairs:\n",
    "    comments = scrape_comments_from_matching_posts(\n",
    "        reddit, song, artist, subreddits, limit=75, max_comments=80\n",
    "    )\n",
    "    final_comments.extend(comments)\n",
    "\n",
    "# Step 5: Save to CSV\n",
    "df_comments = pd.DataFrame(final_comments)\n",
    "df_comments.to_csv(\"reddit_song_artist_comments.csv\", index=False)\n",
    "print(f\"\\n‚úÖ Scraping complete. Total comments collected: {len(df_comments)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec12d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-api-python-client pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0ea6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98645973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "API_KEY = ''\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "\n",
    "def search_video(song, artist):\n",
    "    query = f\"{song} {artist} official video\"\n",
    "    request = youtube.search().list(\n",
    "        q=query,\n",
    "        part=\"snippet\",\n",
    "        maxResults=1,\n",
    "        type=\"video\"\n",
    "    )\n",
    "    response = request.execute()\n",
    "    video_id = response[\"items\"][0][\"id\"][\"videoId\"]\n",
    "    return video_id\n",
    "\n",
    "def get_video_metadata(video_id):\n",
    "    request = youtube.videos().list(\n",
    "        part=\"snippet,statistics\",\n",
    "        id=video_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    item = response[\"items\"][0]\n",
    "    return {\n",
    "        \"video_id\": video_id,\n",
    "        \"title\": item[\"snippet\"][\"title\"],\n",
    "        \"channel\": item[\"snippet\"][\"channelTitle\"],\n",
    "        \"published\": item[\"snippet\"][\"publishedAt\"],\n",
    "        \"description\": item[\"snippet\"][\"description\"],\n",
    "        \"views\": item[\"statistics\"].get(\"viewCount\"),\n",
    "        \"likes\": item[\"statistics\"].get(\"likeCount\"),\n",
    "        \"comments\": item[\"statistics\"].get(\"commentCount\")\n",
    "    }\n",
    "\n",
    "def get_comments(video_id, max_comments=1500):\n",
    "    comments = []\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        videoId=video_id,\n",
    "        maxResults=100,\n",
    "        textFormat=\"plainText\"\n",
    "    )\n",
    "    response = request.execute()\n",
    "    while request and len(comments) < max_comments:\n",
    "        for item in response[\"items\"]:\n",
    "            snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "            comments.append({\n",
    "                \"video_id\": video_id,\n",
    "                \"author\": snippet[\"authorDisplayName\"],\n",
    "                \"comment\": snippet[\"textDisplay\"],\n",
    "                \"likes\": snippet[\"likeCount\"],\n",
    "                \"published\": snippet[\"publishedAt\"]\n",
    "            })\n",
    "        if \"nextPageToken\" in response and len(comments) < max_comments:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=100,\n",
    "                pageToken=response[\"nextPageToken\"],\n",
    "                textFormat=\"plainText\"\n",
    "            )\n",
    "            response = request.execute()\n",
    "        else:\n",
    "            break\n",
    "        time.sleep(0.5)\n",
    "    return pd.DataFrame(comments)\n",
    "\n",
    "def combine_metadata_and_comments(song, artist):\n",
    "    try:\n",
    "        video_id = search_video(song, artist)\n",
    "        metadata = get_video_metadata(video_id)\n",
    "        comments_df = get_comments(video_id, max_comments=1500)\n",
    "\n",
    "        for key, value in metadata.items():\n",
    "            comments_df[key] = value\n",
    "\n",
    "        return comments_df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with {song} by {artist}: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbc0aa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé∂ Fetching data for Apple by Charli xcx...\n",
      "üé∂ Fetching data for BIRDS OF A FEATHER by Billie Eilish...\n",
      "üé∂ Fetching data for Espresso by Sabrina Carpenter...\n",
      "üé∂ Fetching data for Not Like Us by Kendrick Lamar...\n",
      "üé∂ Fetching data for Obsessed by Olivia Rodrigo...\n",
      "üé∂ Fetching data for Too Sweet by Hozier...\n",
      "üé∂ Fetching data for APT by Rose...\n",
      "üé∂ Fetching data for FEIN by Travis Scott...\n",
      "üé∂ Fetching data for Big Dawgs by Hanumankind...\n",
      "üé∂ Fetching data for Mamushi by Meghan Thee Stallion...\n",
      "‚úÖ Scraping completed and saved to 'youtube_song_comments_data_1.csv'\n"
     ]
    }
   ],
   "source": [
    "songs = [\n",
    "    (\"Apple\", \"Charli xcx\"),\n",
    "    (\"BIRDS OF A FEATHER\", \"Billie Eilish\"),\n",
    "    (\"Espresso\", \"Sabrina Carpenter\"),\n",
    "    (\"Not Like Us\", \"Kendrick Lamar\"),\n",
    "    (\"Obsessed\", \"Olivia Rodrigo\"),\n",
    "    (\"Too Sweet\", \"Hozier\"),\n",
    "    (\"APT\", \"Rose\"),\n",
    "    (\"FEIN\", \"Travis Scott\"),\n",
    "    (\"Big Dawgs\", \"Hanumankind\"),\n",
    "    (\"Mamushi\", \"Meghan Thee Stallion\")\n",
    "]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for song, artist in songs:\n",
    "    print(f\"üé∂ Fetching data for {song} by {artist}...\")\n",
    "    df = combine_metadata_and_comments(song, artist)\n",
    "    all_data.append(df)\n",
    "\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "final_df.to_csv(\"youtube_song_comments_data_1.csv\", index=False)\n",
    "print(\"‚úÖ Scraping completed and saved to 'youtube_song_comments_data_1.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49344cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98892966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
